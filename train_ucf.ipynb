{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9362d439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanai-lab/qiu-y/miniconda3/envs/vad/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from model import VADModel\n",
    "from ucf_test import test\n",
    "# from utils.dataset import UCFDataset\n",
    "from utils.tools import get_prompt_text, get_batch_label\n",
    "import ucf_option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c1e3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置变量\n",
    "gt_path = './data/ucf_gt.json'\n",
    "video_feature_list = 'list/ucf_CLIP_rgbtest.csv'\n",
    "gt_txt = 'list/Temporal_Anomaly_Annotation.txt' # ucf的gt文件,介绍了动作区间\n",
    "\n",
    "# 类别名称汇总\n",
    "label_map = {\n",
    "        'Normal': 'normal',\n",
    "        'Abuse': 'abuse',\n",
    "        'Arrest': 'arrest',\n",
    "        'Arson': 'arson',\n",
    "        'Assault': 'assault',\n",
    "        'Burglary': 'burglary',\n",
    "        'Explosion': 'explosion',\n",
    "        'Fighting': 'fighting',\n",
    "        'RoadAccidents': 'roadAccidents',\n",
    "        'Robbery': 'robbery',\n",
    "        'Shooting': 'shooting',\n",
    "        'Shoplifting': 'shoplifting',\n",
    "        'Stealing': 'stealing',\n",
    "        'Vandalism': 'vandalism'\n",
    "    }\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "visual_length = 256   # 每个视频特征的时序长度\n",
    "\n",
    "train_list = 'list/ucf_CLIP_rgb_yanai.csv'  # 训练集列表，包含了地址与标签\n",
    "test_list = 'list/ucf_CLIP_rgbtest_yanai.csv'   # 测试集列表，包含了地址与标签\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b732b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 gt\n",
    "gt = np.load(\"list/gt_ucf.npy\")  # 每个特征文件的时序维度 * 16 * 文件数（290）\n",
    "\n",
    "# 读取 gt_segment 和 gt_label,这两个用于mAP计算\n",
    "gtsegments = np.load('list/gt_segment_ucf.npy', allow_pickle=True)  # 仅表示每个文件中标签所在的时序区间，比如异常动作在哪一段中，如果是正常，那就是全部\n",
    "\n",
    "gtlabels = np.load('list/gt_label_ucf.npy', allow_pickle=True) # 每个文件的类别名称，如果是正常就是A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408d1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "def get_prompt_text(label_map: dict):\n",
    "    # 获取所有类别名称，作为prompt文本输入\n",
    "    prompt_text = []\n",
    "    for v in label_map.values():\n",
    "        prompt_text.append(v)\n",
    "\n",
    "    return prompt_text\n",
    "\n",
    "\n",
    "def process_feat(feat, length, is_random=False):\n",
    "    # 对特征进行截取或填充\n",
    "    clip_length = feat.shape[0]\n",
    "    if feat.shape[0] > length:\n",
    "        if is_random:\n",
    "            return random_extract(feat, length), length\n",
    "        else:\n",
    "            return uniform_extract(feat, length), length\n",
    "    else:\n",
    "        return pad(feat, length), clip_length\n",
    "    \n",
    "\n",
    "def process_split(feat, length):\n",
    "    # 对特征进行分割，在测试时使用\n",
    "    clip_length = feat.shape[0]\n",
    "    if clip_length < length:\n",
    "        return pad(feat, length), clip_length\n",
    "    else:\n",
    "        split_num = int(clip_length / length) + 1\n",
    "        for i in range(split_num):\n",
    "            if i == 0:\n",
    "                split_feat = feat[i*length:i*length+length, :].reshape(1, length, feat.shape[1])\n",
    "            elif i < split_num - 1:\n",
    "                split_feat = np.concatenate([split_feat, feat[i*length:i*length+length, :].reshape(1, length, feat.shape[1])], axis=0)\n",
    "            else:\n",
    "                split_feat = np.concatenate([split_feat, pad(feat[i*length:i*length+length, :], length).reshape(1, length, feat.shape[1])], axis=0)\n",
    "\n",
    "        return split_feat, clip_length\n",
    "    \n",
    "\n",
    "class UCFDataset(data.Dataset):\n",
    "    # UCF数据集读取类\n",
    "    def __init__(self, clip_dim: int, file_path: str, test_mode: bool, label_map: dict, normal: bool = False):\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.clip_dim = clip_dim\n",
    "        self.test_mode = test_mode\n",
    "        self.label_map = label_map\n",
    "        self.normal = normal\n",
    "        if normal == True and test_mode == False:\n",
    "            self.df = self.df.loc[self.df['label'] == 'Normal']\n",
    "            self.df = self.df.reset_index()\n",
    "        elif test_mode == False:\n",
    "            self.df = self.df.loc[self.df['label'] != 'Normal']\n",
    "            self.df = self.df.reset_index()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        clip_feature = np.load(self.df.loc[index]['path'])\n",
    "        if self.test_mode == False:\n",
    "            clip_feature, clip_length = process_feat(clip_feature, self.clip_dim)\n",
    "        else:\n",
    "            clip_feature, clip_length = process_split(clip_feature, self.clip_dim)\n",
    "\n",
    "        clip_feature = torch.tensor(clip_feature)\n",
    "        clip_label = self.df.loc[index]['label']\n",
    "        return clip_feature, clip_label, clip_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ad39a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集正常部分\n",
    "normal_dataset = UCFDataset(clip_dim=visual_length, file_path=train_list, test_mode=False, label_map=label_map, normal=True)\n",
    "normal_loader = DataLoader(normal_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# 训练集异常部分\n",
    "anomaly_dataset = UCFDataset(clip_dim=visual_length, file_path=train_list, test_mode=False, label_map=label_map, normal=False)\n",
    "anomaly_loader = DataLoader(anomaly_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# 测试集\n",
    "test_dataset = UCFDataset(clip_dim=visual_length, file_path=test_list, test_mode=True, label_map=label_map)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# len(normal_dataset): 8000, len(anomaly_dataset): 8100, len(test_dataset): 290\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22a033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanai-lab/qiu-y/miniconda3/envs/vad/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VADModel(\n",
       "  (temporal_attn1): MTCAttentionBlock(\n",
       "    (attn): MultiScaleCompressedAttention(\n",
       "      (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "      (split_heads): Rearrange('b l (h d) -> b h l d', h=8)\n",
       "      (merge_heads): Rearrange('b h l d -> b l (h d)')\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (comp_blk1): CompressionBlock(\n",
       "        (k_comp_mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=32, bias=True)\n",
       "          (1): QuickGELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (v_comp_mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=32, bias=True)\n",
       "          (1): QuickGELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (comp_blk2): CompressionBlock(\n",
       "        (k_comp_mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): QuickGELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (v_comp_mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): QuickGELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (out_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (gate): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=24, bias=True)\n",
       "        (1): Sigmoid()\n",
       "        (2): Rearrange('b l (h s) -> b h l s', h=8)\n",
       "      )\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (gelu): QuickGELU()\n",
       "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    )\n",
       "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (temporal_attn2): MTCAttentionBlock(\n",
       "    (attn): MultiScaleCompressedAttention(\n",
       "      (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "      (split_heads): Rearrange('b l (h d) -> b h l d', h=8)\n",
       "      (merge_heads): Rearrange('b h l d -> b l (h d)')\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (comp_blk1): CompressionBlock(\n",
       "        (k_comp_mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=32, bias=True)\n",
       "          (1): QuickGELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (v_comp_mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=32, bias=True)\n",
       "          (1): QuickGELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (comp_blk2): CompressionBlock(\n",
       "        (k_comp_mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): QuickGELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (v_comp_mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): QuickGELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (out_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (gate): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=24, bias=True)\n",
       "        (1): Sigmoid()\n",
       "        (2): Rearrange('b l (h s) -> b h l s', h=8)\n",
       "      )\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (gelu): QuickGELU()\n",
       "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    )\n",
       "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (temporal_attn3): MTCAttentionBlock(\n",
       "    (attn): MultiScaleCompressedAttention(\n",
       "      (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "      (split_heads): Rearrange('b l (h d) -> b h l d', h=8)\n",
       "      (merge_heads): Rearrange('b h l d -> b l (h d)')\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (comp_blk1): CompressionBlock(\n",
       "        (k_comp_mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=32, bias=True)\n",
       "          (1): QuickGELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (v_comp_mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=32, bias=True)\n",
       "          (1): QuickGELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (comp_blk2): CompressionBlock(\n",
       "        (k_comp_mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): QuickGELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (v_comp_mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): QuickGELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (out_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (gate): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=24, bias=True)\n",
       "        (1): Sigmoid()\n",
       "        (2): Rearrange('b l (h s) -> b h l s', h=8)\n",
       "      )\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (gelu): QuickGELU()\n",
       "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    )\n",
       "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (video_text_fusion1): VideoTextFusion(\n",
       "    (vid_cross_attn): LatentFusionAttention(\n",
       "      (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (kv_proj): Linear(in_features=512, out_features=1024, bias=False)\n",
       "      (q_lora_proj): Linear(in_features=512, out_features=128, bias=False)\n",
       "      (kv_lora_proj): Linear(in_features=512, out_features=256, bias=False)\n",
       "      (fuse_proj): Linear(in_features=640, out_features=512, bias=False)\n",
       "      (split_heads): Rearrange('b l (h d) -> b h l d', h=8)\n",
       "      (merge_heads): Rearrange('b h l d -> b l (h d)')\n",
       "      (A_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (B_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (out_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (txt_cross_attn): LatentFusionAttention(\n",
       "      (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (kv_proj): Linear(in_features=512, out_features=1024, bias=False)\n",
       "      (q_lora_proj): Linear(in_features=512, out_features=128, bias=False)\n",
       "      (kv_lora_proj): Linear(in_features=512, out_features=256, bias=False)\n",
       "      (fuse_proj): Linear(in_features=640, out_features=512, bias=False)\n",
       "      (split_heads): Rearrange('b l (h d) -> b h l d', h=8)\n",
       "      (merge_heads): Rearrange('b h l d -> b l (h d)')\n",
       "      (A_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (B_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (out_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (norm_vid): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm_txt): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (prompt_enhance_module): PromptEnhanceModule(\n",
       "    (mllm): DebertaV2Model(\n",
       "      (embeddings): DebertaV2Embeddings(\n",
       "        (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): DebertaV2Encoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x DebertaV2Layer(\n",
       "            (attention): DebertaV2Attention(\n",
       "              (self): DisentangledSelfAttention(\n",
       "                (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): DebertaV2SelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): DebertaV2Intermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): DebertaV2Output(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (rel_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (out_proj): Linear(in_features=768, out_features=512, bias=False)\n",
       "  )\n",
       "  (frame_position_embeddings): Embedding(256, 512)\n",
       "  (mlp1): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    (1): QuickGELU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  )\n",
       "  (mlp2): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    (1): QuickGELU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建模型\n",
    "cls_num = len(label_map)  # 类别数量\n",
    "embed_dim = 512  # 特征维度\n",
    "visual_width = 512 # 每个时间步的视觉特征维度\n",
    "visual_head = 1  # 视觉特征的头数\n",
    "prompt_prefix = 10  # prompt增强维度\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# 加载模型，虽然模型的构建也有些问题，但是先不管！\n",
    "model = VADModel(\n",
    "    cls_num,\n",
    "    embed_dim,\n",
    "    visual_length,\n",
    "    visual_width,\n",
    "    prompt_prefix,\n",
    "    device\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2fad68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
