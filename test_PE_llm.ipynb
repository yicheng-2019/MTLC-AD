{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b559892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanai-lab/qiu-y/miniconda3/envs/vad/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    DebertaV2Tokenizer, DebertaV2Model,\n",
    "    AutoTokenizer, AutoModel\n",
    ")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38662b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['normal', 'abuse', 'arrest', 'arson', 'assault', 'burglary', 'explosion', 'fighting', 'roadAccidents', 'robbery', 'shooting', 'shoplifting', 'stealing', 'vandalism'], total 14 classes.\n"
     ]
    }
   ],
   "source": [
    "vid_mllm_ckpt = \"/export/space0/qiu-y/model/deberta-v3-base\"\n",
    "device = \"cuda:0\"\n",
    "cls_names = [\n",
    "        'normal', 'abuse', 'arrest', 'arson', 'assault',\n",
    "        'burglary', 'explosion', 'fighting', 'roadAccidents',\n",
    "        'robbery', 'shooting', 'shoplifting', 'stealing', 'vandalism']\n",
    "cls_num = len(cls_names)\n",
    "\n",
    "learnable_prompt_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59e06478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanai-lab/qiu-y/miniconda3/envs/vad/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mllm = AutoModel.from_pretrained(vid_mllm_ckpt).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(vid_mllm_ckpt)\n",
    "model_hidden = mllm.config.hidden_size  # 768\n",
    "# seq_max = min(256, mllm.config.max_position_embeddings)\n",
    "seq_max = 77\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d118c652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 57]) torch.Size([14, 57])\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer(\n",
    "            cls_names,\n",
    "            max_length=int(seq_max - 2 * learnable_prompt_len),\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "word_tokens = encoded[\"input_ids\"]\n",
    "attn_mask = encoded['attention_mask'].to(device)\n",
    "print(word_tokens.shape, attn_mask.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb24d7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 57, 768])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embed = mllm.get_input_embeddings()\n",
    "word_emb = token_embed(word_tokens.to(device))\n",
    "word_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dcc7928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 10, 768]) torch.Size([14, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "prefix = nn.Parameter(torch.randn(cls_num, learnable_prompt_len, model_hidden) * 0.02).to(device)\n",
    "suffix = nn.Parameter(torch.randn(cls_num, learnable_prompt_len, model_hidden) * 0.02).to(device)\n",
    "print(prefix.shape, suffix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2158650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 77, 768])\n"
     ]
    }
   ],
   "source": [
    "inputs_embeds = torch.cat([prefix, word_emb, suffix], dim=1)\n",
    " \n",
    "print(inputs_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ecab833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 10])\n",
      "torch.Size([14, 77])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(cls_num, learnable_prompt_len, device=device, dtype=attn_mask.dtype)\n",
    "print(ones.shape)\n",
    "attn_mask = torch.cat([ones, attn_mask, ones], dim=1)  \n",
    "print(attn_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea4776d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 77, 768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 送入模型（模型内部统一加位置编码；不要再手工加位置）\n",
    "out = mllm(inputs_embeds=inputs_embeds, attention_mask=attn_mask)\n",
    "out.last_hidden_state.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
